{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiantianWang-Sara/Machine-Learning-Projects/blob/main/FIN553_2024_Graded_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Due date:\n",
        "October 11\n",
        "\n",
        "# Problem statement\n",
        "\n",
        "You are part of a trading team that makes investments based on [Fundamental Analysis](https://https://en.wikipedia.org/wiki/Fundamental_analysis).\n",
        "\n",
        "Your job is to produce revenue growth forecasts for firms in a given industry based on financial charateristics of these firms and relevant economic data. Your forecasts are then used in a larger decision making system.\n",
        "\n",
        "You have access to a dataset of 15,000 observations. Each observation $(X_i, y_i)$ consists of 4,000 economic and financial indicators that could presumably forecast revenue growth for the next quarter, and the corresponding revenue growth for that observation ($y_i$).\n",
        "\n",
        "The corresponding data set is given below:\n",
        "\n",
        "X.npy: https://drive.google.com/file/d/1SbC0xE1PPK0gL6J2yolIaQ07eoNVk2bM\n",
        "\n",
        "\n",
        "y.py: https://drive.google.com/file/d/1HxnGlU_epSaiDppRCzkZAX8AJIkV0xvS\n",
        "\n",
        "\n",
        "# Task\n",
        "Construct a linear model to forecast revenue growth based on the data you have. You model will be evaluated based on the mean squared error between your predictions and the labels evaluated at a test set. The test set comes from the same distribution as the training set and the evaluation set.\n",
        "\n"
      ],
      "metadata": {
        "id": "W14vyBYt8eE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deliverables\n",
        "You should send me the entire code used to solve the problem. You can send me either a colab link or a single .py file.\n",
        "\n",
        "As part of you solution, you should also deliver a function.\n"
      ],
      "metadata": {
        "id": "Uz7GKYDVX3St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from google.colab import drive\n",
        "import jax\n",
        "import optax\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmaMZiAnZdUa",
        "outputId": "d153aea8-706a-4576-cc9d-d2ef9b99426f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=jnp.load(\"X.npy\")\n",
        "y=jnp.load(\"y.npy\")"
      ],
      "metadata": {
        "id": "wan-rLU0BFpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stack(θ):\n",
        "  return jnp.array([θ] * n_models)\n",
        "\n",
        "def f(X, θ):\n",
        "  return jnp.dot(X, θ)\n",
        "\n",
        "def loss(θ,λ):\n",
        "  return jnp.mean((f(X, θ) - y)**2 + λ*(abs(θ)).sum())\n",
        "\n",
        "def sample():\n",
        "  batch_size = 10000\n",
        "  idx = np.random.choice(N, batch_size)\n",
        "  return X[idx], y[idx]\n",
        "\n",
        "grad_loss = jax.grad(loss)\n",
        "\n",
        "@jax.jit\n",
        "def update(θ, opt_state, X, y, α, beta, beta2,λ):\n",
        "  grad = grad_loss(θ,λ)\n",
        "  optimizer = optax.adam(α, beta, beta2)\n",
        "  updates, opt_state = optimizer.update(grad, opt_state)\n",
        "  θ = optax.apply_updates(θ, updates)\n",
        "  return θ, opt_state\n",
        "\n",
        "α = 0.001\n",
        "beta = 0.9\n",
        "beta2 = 0.999"
      ],
      "metadata": {
        "id": "B2_S4YCRXGHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = X.shape[0]\n",
        "idx = np.random.choice(N, int(N*0.2),replace=False)\n",
        "\n",
        "X_test = X[idx]\n",
        "y_test = y[idx]\n",
        "\n",
        "X = jnp.delete(X, idx, axis=0)\n",
        "y = jnp.delete(y, idx)"
      ],
      "metadata": {
        "id": "hxwijcqhmJJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding best lambda, skip if takes long time\n",
        "\n",
        "@jax.jit\n",
        "@jax.vmap\n",
        "def mse(θ):\n",
        "  return jnp.mean((f(X_test, θ) - y_test)**2)\n",
        "\n",
        "update = jax.jit(jax.vmap(update, in_axes=(0, 0, None, None, None, None, None, 0)))\n",
        "\n",
        "θ = jnp.zeros(X.shape[1])\n",
        "\n",
        "n_models = 100\n",
        "\n",
        "opt_state = optax.adam(α, beta, beta2).init(θ)\n",
        "θ = stack(θ)\n",
        "opt_state = jax.tree.map(stack, opt_state)\n",
        "N = X.shape[0]\n",
        "\n",
        "low = 0\n",
        "high = 1\n",
        "\n",
        "for i in range(10):\n",
        "  λ = np.array(np.sort(np.hstack([np.random.uniform(low, high, n_models-2),[low,high]])))\n",
        "  θ = jnp.zeros(X.shape[1])\n",
        "  opt_state = optax.adam(α, beta, beta2).init(θ)\n",
        "  θ = stack(θ)\n",
        "  opt_state = jax.tree.map(stack, opt_state)\n",
        "  for iteration in range(10000):\n",
        "    Xi, yi = sample()\n",
        "    θ, opt_state = update(θ, opt_state, Xi, yi, α, beta, beta2,λ)\n",
        "  mse_number = mse(θ)\n",
        "  idx= np.argmin(mse_number)\n",
        "  optimal = λ[idx]\n",
        "  if idx == 0:\n",
        "    low = λ[idx]\n",
        "    high = λ[idx+1]\n",
        "  elif idx == 99:\n",
        "    low = λ[idx-1]\n",
        "    high = λ[idx]\n",
        "  else:\n",
        "    low = λ[idx-1]\n",
        "    high = λ[idx+1]\n",
        "  print(optimal)"
      ],
      "metadata": {
        "id": "6HcpWPM0Z41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c34a415-2019-4dca-a357-2307f252b383",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.001020432577526862\n",
            "0.0011034309819248753\n",
            "0.0011124879062249372\n",
            "0.0011130614350518665\n",
            "0.0011130614463100207\n",
            "0.0011130613895146226\n",
            "0.0011130613857435827\n",
            "0.0011130613856957631\n",
            "0.0011130613856949578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=jnp.load(\"X.npy\")\n",
        "y=jnp.load(\"y.npy\")\n",
        "θ = jnp.zeros(X.shape[1])\n",
        "opt_state = optax.adam(α, beta, beta2).init(θ)\n",
        "\n",
        "@jax.jit\n",
        "def update(θ, opt_state, X, y, α, beta, beta2,λ):\n",
        "  grad = grad_loss(θ,λ)\n",
        "  optimizer = optax.adam(α, beta, beta2)\n",
        "  updates, opt_state = optimizer.update(grad, opt_state)\n",
        "  θ = optax.apply_updates(θ, updates)\n",
        "  return θ, opt_state\n",
        "\n",
        "try:\n",
        "  λ = optimal\n",
        "except:\n",
        "  λ = 0.0005 # After testing, we estimate this value will be the best.\n",
        "\n",
        "print(λ)\n",
        "\n",
        "def update(θ, opt_state, X, y, α, beta, beta2,λ):\n",
        "  grad = grad_loss(θ,λ)\n",
        "  optimizer = optax.adam(α, beta, beta2)\n",
        "  updates, opt_state = optimizer.update(grad, opt_state)\n",
        "  θ = optax.apply_updates(θ, updates)\n",
        "  return θ, opt_state\n",
        "\n",
        "for iteration in range(10000):\n",
        "  Xi, yi = sample()\n",
        "  θ, opt_state = update(θ, opt_state, Xi, yi, α, beta, beta2,λ)\n",
        "\n",
        "  if iteration % 1000 == 0:\n",
        "    print(θ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV7bNmtTd_og",
        "outputId": "7d39af5a-bf90-4221-ec59-de4fd7e0d65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0011130613856949578\n",
            "[-0.00099999 -0.00099999  0.00099999 ... -0.00099999  0.00099999\n",
            " -0.00099999]\n",
            "[-0.8613272  -0.5595428   0.88259137 ... -0.00617992  0.0072826\n",
            " -0.00466918]\n",
            "[-1.5502613  -0.11304063  1.6991305  ... -0.00245418  0.00575801\n",
            " -0.00268312]\n",
            "[-2.1400676e+00  7.3420894e-01  2.3306179e+00 ... -4.8147759e-04\n",
            "  3.8450016e-03 -1.4240554e-03]\n",
            "[-2.6283228e+00  1.6936095e+00  2.8356528e+00 ...  1.6224492e-04\n",
            "  1.9775473e-03 -3.0377480e-05]\n",
            "[-3.0043218e+00  2.6291127e+00  3.2306387e+00 ...  2.2768902e-04\n",
            "  7.8674476e-04 -2.4365055e-04]\n",
            "[-3.2749345e+00  3.4762940e+00  3.4778061e+00 ...  2.9893732e-04\n",
            "  9.8539836e-05 -1.1413362e-04]\n",
            "[-3.4665723e+00  4.2396989e+00  3.5513141e+00 ...  2.7967207e-04\n",
            " -1.6171644e-04  2.5095843e-04]\n",
            "[-3.6056838e+00  4.9246049e+00  3.3389261e+00 ...  2.3610330e-04\n",
            " -4.3844229e-05  1.4751423e-04]\n",
            "[-3.7113843e+00  5.5821447e+00  2.8458681e+00 ... -8.2906510e-05\n",
            " -6.5397347e-05  2.8547319e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(X):\n",
        "  prediction = jnp.dot(X,θ)\n",
        "  return prediction\n"
      ],
      "metadata": {
        "id": "O1fcw8Gu8fTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "that returns the predictions of you model for a new dataset X.\n"
      ],
      "metadata": {
        "id": "0HYsGt6WYtLW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pie-6cI3Yukf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}